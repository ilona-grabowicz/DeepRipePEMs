{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepare bed files with coordinates\n",
    "\n",
    "def prepare_bed_files(de_file, FDR, region, dist_from_TSS):\n",
    "    \n",
    "    m = open('DeSeq2_'+de_file+'.csv', 'r').readlines()\n",
    "    \n",
    "    de_up = [l.strip().split('\\t')[0][0:15] for l in m[1:] if l.strip().split('\\t')[6]!='NA' \n",
    "          and float(l.strip().split('\\t')[6])<FDR \n",
    "         and float(l.strip().split('\\t')[2])>0] # positive log2FC (=higher expression) in the first grade of the two compared\n",
    "    de_down = [l.strip().split('\\t')[0][0:15] for l in m[1:] if l.strip().split('\\t')[6]!='NA' \n",
    "          and float(l.strip().split('\\t')[6])<FDR \n",
    "         and float(l.strip().split('\\t')[2])<0] # negative log2FC (=lower expression) in the first grade of the two compared\n",
    "    g = open('hg38_'+region+'_'+de_file+'_up.bed', 'w')\n",
    "    h = open('hg38_'+region+'_'+de_file+'_down.bed', 'w')\n",
    "    if region == 'promoters':\n",
    "        f = open('hg38_genes.bed', 'r').readlines()\n",
    "        for line in f:\n",
    "            line = line.strip().split('\\t')\n",
    "            if line[3] in de_up: # check whether the gene is Differentially Expressed\n",
    "                if line[5]=='+':\n",
    "                    g.write(line[0]+'\\t'+str(int(line[1])-dist_from_TSS)+'\\t'+str(int(line[1])+dist_from_TSS)+'\\t'+line[3]+'\\t'+line[4]+'\\t'+line[5]+'\\n')\n",
    "                if line[5]=='-':\n",
    "                    g.write(line[0]+'\\t'+str(int(line[2])-dist_from_TSS)+'\\t'+str(int(line[2])+dist_from_TSS)+'\\t'+line[3]+'\\t'+line[4]+'\\t'+line[5]+'\\n')\n",
    "            if line[3] in de_down:\n",
    "                if line[5]=='+':\n",
    "                    h.write(line[0]+'\\t'+str(int(line[1])-dist_from_TSS)+'\\t'+str(int(line[1])+dist_from_TSS)+'\\t'+line[3]+'\\t'+line[4]+'\\t'+line[5]+'\\n')\n",
    "                if line[5]=='-':\n",
    "                    h.write(line[0]+'\\t'+str(int(line[2])-dist_from_TSS)+'\\t'+str(int(line[2])+dist_from_TSS)+'\\t'+line[3]+'\\t'+line[4]+'\\t'+line[5]+'\\n')\n",
    "    if region == 'enhancers':\n",
    "        f = open('hg38_enhancers.bed', 'r').readlines()\n",
    "        for line in f:\n",
    "            line = line.strip().split('\\t')\n",
    "            if line[3] in de_up: \n",
    "                g.write('\\t'.join(line)+'\\n')\n",
    "            if line[3] in de_down:\n",
    "                h.write('\\t'.join(line)+'\\n')\n",
    "prepare_bed_files('grade1_grade23', 0.01, 'enhancers', 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run bedtools to generate fasta files with the desired sequences\n",
    "import os\n",
    "\n",
    "def get_fasta_files(de_file, region, up_or_down):\n",
    "    comm = os.popen('bedtools getfasta -fi hg38.fa -bed hg38_'+region+'_'+de_file+'_'+up_or_down+'.bed -fo '+de_file+'_'+region+'_seq_'+up_or_down+'.fa')\n",
    "    comm.read()\n",
    "    comm.close()\n",
    "#get_fasta_files('grade1_grade23', 'promoter', 'up')\n",
    "get_fasta_files('grade1_grade23', 'enhancers', 'down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "############################################\n",
    "### Function to load data in h5py format ###\n",
    "############################################\n",
    "\n",
    "'''def load_data(path_to_data):\n",
    "    data = h5py.File(path_to_data,'r')\n",
    "    X_test_seq = np.transpose(np.array(data['test_in_seq']),axes=(0,2,1))\n",
    "    X_test_region = np.transpose(np.array(data['test_in_region']),axes=(0,2,1))\n",
    "    y_test_RBP = np.array(data['test_out'])\n",
    "    y_test_name= np.array(data['test_name'])\n",
    "    y_train= np.array(data['train_out'])\n",
    "    data.close()\n",
    "\n",
    "    return X_test_seq, X_test_region, y_test_RBP, y_test_name, y_train'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the promoter sequences into shorter sequences, which will be the input for the model.\n",
    "def split_into_short_sequences(de_file, region, up_or_down, short_seq_length, step):\n",
    "    long_sequence_file = open(de_file+'_'+region+'_seq_'+up_or_down+'.fa', 'r').readlines()\n",
    "    short_seq_list = []\n",
    "    for long_seq in long_sequence_file:\n",
    "        if '>' not in long_seq:\n",
    "            long_seq = long_seq.strip()\n",
    "            for x in range(0, len(long_seq), step): #97?\n",
    "                short_seq = long_seq[x:x+short_seq_length]\n",
    "                #print(short_seq)\n",
    "                short_seq_list.append(short_seq)\n",
    "    return short_seq_list\n",
    "grade1_23_promoter_up = split_into_short_sequences('grade1_grade23', 'promoter', 'up', 150, 20)\n",
    "grade1_23_promoter_down = split_into_short_sequences('grade1_grade23', 'promoter', 'down', 150, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(grade1_23_promoter_up)\n",
    "grade1_23_promoter_up = grade1_23_promoter_up[0:50] #I'm using less sequences just for the sake of speed of testing\n",
    "len(grade1_23_promoter_up)\n",
    "grade1_23_promoter_down = grade1_23_promoter_down[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "### Function to generate random 'region' sequences     ###\n",
    "##########################################################\n",
    "\n",
    "def generate_random_regions(seq_len, nr_of_seqs): # Generate random regions, just for testing\n",
    "    test_in_region = []\n",
    "    for nr in range(nr_of_seqs):\n",
    "        single_reg = ''.join([random.choice(['i', '3', '5']) for i in range(seq_len)])\n",
    "        test_in_region.append(single_reg)\n",
    "    return test_in_region\n",
    "\n",
    "grade1_23_promoter_up_region = generate_random_regions(250, 50)\n",
    "grade1_23_promoter_down_region = generate_random_regions(250, 50)\n",
    "#print(grade1_23_promoter_up_region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##########################################################\n",
    "### Function to generate random nucleotide sequences   ###\n",
    "##########################################################\n",
    "\n",
    "'''def generate_random_sequence(seq_len, nr_of_seqs): # Generate random sequence, just for testing\n",
    "    test_in_seq = []\n",
    "    for nr in range(nr_of_seqs):\n",
    "        single_seq = ''.join([random.choice(['A', 'T', 'G', 'C', 'a', 't', 'g', 'c']) for i in range(seq_len)])\n",
    "        test_in_seq.append(single_seq)\n",
    "    return test_in_seq\n",
    "\n",
    "test_in_seq_rand = generate_random_sequence(150, 15) # Te liczby tzn 150 i 250 dla regions musza takie byc inaczej models.py nie hula.\n",
    "\n",
    "train_in_seq_rand = generate_random_sequence(150, 15)\n",
    "print(train_in_seq_rand)\n",
    "valid_in_seq_rand = generate_random_sequence(150, 15)\n",
    "#train_in_region = generate_random_regions(250, 15)\n",
    "#valid_in_region = generate_random_regions(250, 15)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "\n",
    "##########################################################\n",
    "### Function to convert the sequence to one-hot encode ### # taken from Deep-Ripe scripts\n",
    "##########################################################\n",
    "\n",
    "def seq_to_mat(seq):\n",
    "    seq_len = len(seq)\n",
    "    seq = seq.replace('A','0')\n",
    "    seq = seq.replace('a','0')\n",
    "    seq = seq.replace('C','1')\n",
    "    seq = seq.replace('c','1')\n",
    "    seq = seq.replace('G','2')\n",
    "    seq = seq.replace('g','2')\n",
    "    seq = seq.replace('T','3')\n",
    "    seq = seq.replace('t','3')\n",
    "    seq = seq.replace('U','3')\n",
    "    seq = seq.replace('u','3')\n",
    "    seq = seq.replace('N','4') #some cases have N in sequence\n",
    "    seq = seq.replace('n','4')\n",
    "    seq_code = np.zeros((4,seq_len), dtype='float16')\n",
    "    for i in range(seq_len):\n",
    "        if int(seq[i]) != 4:\n",
    "            seq_code[int(seq[i]),i] = 1\n",
    "        else:\n",
    "            seq_code[0:4,i] = np.tile(0.25,4)\n",
    "    return np.transpose(seq_code)\n",
    "\n",
    "##########################################################\n",
    "### Function to convert the region to one-hot encode ###\n",
    "##########################################################\n",
    "\n",
    "def region_to_mat(region):\n",
    "    region_len = len(region)\n",
    "    region= region.replace('i','0')\n",
    "    region= region.replace('c','1')\n",
    "    region= region.replace('3','2')\n",
    "    region= region.replace('5','3')\n",
    "    region= region.replace('N','4')\n",
    "    region_code = np.zeros((4,region_len), dtype='float16')\n",
    "    for i in range(region_len):\n",
    "        if int(region[i]) != 4:\n",
    "            region_code[int(region[i]),i] = 1\n",
    "        else:\n",
    "            region_code[0:4,i] = np.tile(0.25,4)\n",
    "    return np.transpose(region_code)\n",
    "import random\n",
    "import h5py\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "### Function to split the sequences into 4 separate arrays ###\n",
    "##############################################################\n",
    "#print(test_in_seq)\n",
    "#print(np.array(test_in_seq_rand))\n",
    "def split_into_4_arrays(input_list):\n",
    "    for j in range(len(input_list)):\n",
    "        sekw = input_list[j].strip()\n",
    "        if sekw[0] in ['A', 'C', 'G', 'T', 'U', 'a', 'c', 'g', 't', 'u']:\n",
    "            sekw = seq_to_mat(sekw)\n",
    "        elif sekw[0] in ['i', '3', '5']:\n",
    "            sekw = region_to_mat(sekw)\n",
    "        sekw = np.array([sekw[:,0], sekw[:,1], sekw[:,2], sekw[:,3]])\n",
    "        input_list[j] = sekw\n",
    "    result = np.array(input_list)\n",
    "    return result\n",
    "\n",
    "#test_in_seq1 = split_into_4_arrays(['AAAGGGCCCTTTTT', 'AAAGGGCCCGGGGG'])\n",
    "grade1_23_promoter_up_one_hot = split_into_4_arrays(grade1_23_promoter_up)\n",
    "grade1_23_promoter_down_one_hot =  split_into_4_arrays(grade1_23_promoter_down)\n",
    "grade1_23_promoter_up_one_hot_region = split_into_4_arrays(grade1_23_promoter_up_region)\n",
    "grade1_23_promoter_down_one_hot_region =  split_into_4_arrays(grade1_23_promoter_down_region)\n",
    "#test_name = np.array([random.choice(string.ascii_letters) for i in range(len(test_in_seq))], dtype='S')\n",
    "#print(type(test_in_seq1))\n",
    "#print(type(np.array(test_in_seq_rand)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 4, 150)\n",
      "50\n",
      "(50, 4, 250)\n",
      "50\n",
      "[[[0. 1. 1. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 1.]]\n",
      "\n",
      " [[1. 1. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 1. 1. 1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 1. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  [1. 0. 0. ... 1. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 1. 0.]\n",
      "  [1. 1. 1. ... 0. 0. 1.]]\n",
      "\n",
      " [[1. 0. 0. ... 1. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 1. 0. ... 0. 1. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "print(grade1_23_promoter_up_one_hot.shape)\n",
    "print(len(grade1_23_promoter_up_one_hot))\n",
    "print(grade1_23_promoter_up_one_hot_region.shape)\n",
    "print(len(grade1_23_promoter_up_one_hot_region))\n",
    "print(grade1_23_promoter_up_one_hot_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1']\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#### Create labels from the data\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "labels = ['0' for lab in range(len(grade1_23_promoter_up_one_hot))] +\\\n",
    "['1' for lab in range(len(grade1_23_promoter_down_one_hot))]\n",
    "labels = np.array(labels)\n",
    "print(labels)\n",
    "# one hot encoded labels\n",
    "labels = to_categorical(labels)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4, 150)\n",
      "(20, 4, 150)\n",
      "(70, 4, 150)\n",
      "(70, 2)\n"
     ]
    }
   ],
   "source": [
    "### Splitting the data into training 70%, validation 20% and testing 10%\n",
    "\n",
    "import numpy\n",
    "numpy.random.seed(0)\n",
    "liczba_do_losowania = len(grade1_23_promoter_up_one_hot) + len(grade1_23_promoter_down_one_hot)\n",
    "indices = np.random.permutation(liczba_do_losowania)\n",
    "\n",
    "indices_train = indices[0:int(liczba_do_losowania*0.7)]\n",
    "indices_valid = indices[int(liczba_do_losowania*0.7) : int(liczba_do_losowania*0.9)]\n",
    "indices_test = indices[int(liczba_do_losowania*0.9):]\n",
    "\n",
    "data = np.concatenate((grade1_23_promoter_up_one_hot, grade1_23_promoter_down_one_hot), axis=0)\n",
    "#print(grade1_23_promoter_up_one_hot)\n",
    "#print(indices_train)\n",
    "#print(data[3,])\n",
    "train_in_seq = data[indices_train]\n",
    "valid_in_seq = data[indices_valid]\n",
    "test_in_seq = data[indices_test]\n",
    "\n",
    "train_out = labels[indices_train]\n",
    "valid_out = labels[indices_valid]\n",
    "test_out = labels[indices_test]\n",
    "print(test_in_seq.shape)\n",
    "print(valid_in_seq.shape)\n",
    "print(train_in_seq.shape)\n",
    "print(train_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = np.concatenate((grade1_23_promoter_up_one_hot_region, grade1_23_promoter_down_one_hot_region), axis=0)\n",
    "train_in_region = region[indices_train]\n",
    "valid_in_region = region[indices_valid]\n",
    "test_in_region = region[indices_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_name = np.array([random.choice(string.ascii_letters) for i in range(len(test_in_seq))], dtype='S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def generate_out(nr_of_seqs):\\n    result = []\\n    for k in range(nr_of_seqs):\\n        lista = random.choices([0,1], [0.5, 0.5], k=27)\\n        result.append(lista)\\n    return np.array(result)\\ntest_out = generate_out(15)\\ntrain_out = generate_out(15)\\nvalid_out = generate_out(15)'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################################################\n",
    "### Function to generate random labels dataset      ###\n",
    "#######################################################\n",
    "\n",
    "'''def generate_out(nr_of_seqs):\n",
    "    result = []\n",
    "    for k in range(nr_of_seqs):\n",
    "        lista = random.choices([0,1], [0.5, 0.5], k=27)\n",
    "        result.append(lista)\n",
    "    return np.array(result)\n",
    "test_out = generate_out(15)\n",
    "train_out = generate_out(15)\n",
    "valid_out = generate_out(15)'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['test_in_region', 'test_in_seq', 'test_name', 'test_out', 'train_in_region', 'train_in_seq', 'train_out', 'valid_in_region', 'valid_in_seq', 'valid_out']>\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "### Creating the .h5 file with the input for the model ###\n",
    "##########################################################\n",
    "\n",
    "with h5py.File('test3.h5', 'w') as data_file:\n",
    "    data_file.create_dataset('test_in_region', data = test_in_region)\n",
    "    data_file.create_dataset('test_in_seq', data = test_in_seq)\n",
    "    data_file.create_dataset('test_name', data = test_name)\n",
    "    data_file.create_dataset('test_out', data = test_out)\n",
    "    data_file.create_dataset('train_in_region', data = train_in_region)\n",
    "    data_file.create_dataset('train_in_seq', data = train_in_seq)\n",
    "    data_file.create_dataset('train_out', data = train_out)\n",
    "    data_file.create_dataset('valid_in_region', data = valid_in_region)\n",
    "    data_file.create_dataset('valid_in_seq', data = valid_in_seq)\n",
    "    data_file.create_dataset('valid_out', data = valid_out)\n",
    "data_file.close()\n",
    "# Testing whether it works:\n",
    "data1 = h5py.File('test3.h5','r')\n",
    "X_test_seq = np.array(data1['test_in_seq'])\n",
    "print(data1.keys())\n",
    "#print(data1['test_name'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
